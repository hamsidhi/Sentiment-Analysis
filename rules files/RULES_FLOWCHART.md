# ðŸŽ¯ RULES USAGE FLOWCHART & GUIDE

## When You're Starting a Task - Which Document to Open?

```
START HERE
    |
    â”œâ”€â†’ "I just got this project"
    |       â””â”€â†’ READ: README_RULES.md (complete overview)
    |           Then: PROJECT_RULES.md (Project Structure)
    |
    â”œâ”€â†’ "I need to write Python code"
    |       â””â”€â†’ CHECK: CODE_QUALITY_RULES.md
    |           COPY: Naming conventions & docstring examples
    |           VERIFY: Type hints, error handling
    |
    â”œâ”€â†’ "I need to load/process data"
    |       â””â”€â†’ CHECK: DATA_MODEL_RULES.md
    |           FOLLOW: Data validation checklist
    |           REMEMBER: raw/ is read-only!
    |
    â”œâ”€â†’ "I need to train a model"
    |       â””â”€â†’ CHECK: DATA_MODEL_RULES.md
    |           FOLLOW: Model training setup
    |           SAVE: Model with metadata
    |
    â”œâ”€â†’ "I need to write tests"
    |       â””â”€â†’ CHECK: TESTING_DEPLOYMENT_RULES.md
    |           COPY: Test class template
    |           TARGET: 80%+ coverage
    |
    â”œâ”€â†’ "I'm ready to commit code"
    |       â””â”€â†’ CHECK: QUICK_REFERENCE.md
    |           RUN: Pre-commit checklist
    |
    â””â”€â†’ "I'm ready to deploy"
            â””â”€â†’ CHECK: TESTING_DEPLOYMENT_RULES.md
                RUN: Pre-deployment checklist
```

---

## Document Quick Links

### ðŸ”´ CRITICAL ISSUES? Start Here:

| Issue | Document | Section |
|-------|----------|---------|
| "Is this allowed?" | PROJECT_RULES.md | "DON'T" section |
| "How do I name this?" | CODE_QUALITY_RULES.md | Naming Conventions |
| "Can I modify raw data?" | DATA_MODEL_RULES.md | Data Integrity |
| "How do I save models?" | DATA_MODEL_RULES.md | Model Versioning |
| "What tests do I write?" | TESTING_DEPLOYMENT_RULES.md | Unit Testing |
| "Is my code ready?" | TESTING_DEPLOYMENT_RULES.md | Pre-Deployment |

---

## Daily Usage Pattern

### ðŸŒ… Morning (5 minutes)
```
1. Open: QUICK_REFERENCE.md
2. Check: Quick Start Checklist (your task)
3. Remember: Critical Rules section
4. Open: Specific rule document for your task
```

### ðŸ’» Coding (ongoing)
```
1. Before writing: Check naming conventions
2. While writing: Copy docstring template
3. Before testing: Reference error handling examples
4. Before commit: Run pre-commit checklist
```

### ðŸŒ™ Evening (before committing)
```
1. Run tests: pytest tests/
2. Check coverage: pytest --cov=src tests/
3. Verify: QUICK_REFERENCE.md Pre-Commit Checklist
4. Commit with meaningful message
```

---

## Code Writing Workflow

### Step 1: Plan (2 min)
```
Check: PROJECT_RULES.md
Where should this file go?
  src/              â†’ Main code
  tests/            â†’ Test code
  utils/            â†’ Helper functions
  config/           â†’ Configuration
```

### Step 2: Start (5 min)
```
Check: CODE_QUALITY_RULES.md
Copy template:
  - Naming convention
  - Type hints
  - Docstring (Google style)
  - Error handling pattern
```

### Step 3: Write (30+ min)
```
Follow: CODE_QUALITY_RULES.md
- Use snake_case for variables
- PascalCase for classes
- UPPERCASE for constants
- Keep functions < 50 lines
- Validate inputs
- Handle errors
- Use logging (not print)
```

### Step 4: Test (10+ min)
```
Check: TESTING_DEPLOYMENT_RULES.md
- Write unit tests
- Test edge cases
- Test error conditions
- Run: pytest --cov=src tests/
- Target: 80%+ coverage
```

### Step 5: Review (5 min)
```
Check: QUICK_REFERENCE.md
- Code follows naming conventions âœ“
- Functions have type hints âœ“
- Docstrings complete âœ“
- Tests pass âœ“
- No hardcoded paths âœ“
- No print statements âœ“
- Clear variable names âœ“
```

### Step 6: Commit (2 min)
```
git add .
git commit -m "[Feature] Description of changes"
```

---

## Common Task Workflows

### WORKFLOW 1: Load & Process Data

```
1. Check: DATA_MODEL_RULES.md
   - Data pipeline standards
   - Validation rules
   - Preprocessing examples

2. Steps:
   a) Load from data/raw/
   b) Validate (check columns, types, nulls)
   c) Process (clean text, handle missing)
   d) Save to data/processed/ with metadata
   e) Log statistics

3. Save with metadata:
   {
     "source": "data/raw/reviews_2025_12_24.csv",
     "processing_steps": [
       "Removed 5 null values",
       "Cleaned special characters",
       "Balanced classes (50/50)"
     ],
     "rows": 1000,
     "columns": ["text", "sentiment"]
   }

4. Verify: Use examples from DATA_MODEL_RULES.md
```

### WORKFLOW 2: Train a Model

```
1. Check: DATA_MODEL_RULES.md (Model Training)
   - Setup checklist
   - Train/test split
   - Hyperparameter tracking

2. Steps:
   a) Set random seeds (reproducibility!)
   b) Load processed data
   c) Split: 70% train, 15% val, 15% test
   d) Train model
   e) Evaluate
   f) Save with metadata

3. Save model with metadata:
   {
     "model_type": "logistic_regression",
     "version": "1.0",
     "date": "2025-12-24",
     "accuracy": 0.85,
     "precision": 0.83,
     "recall": 0.82,
     "f1_score": 0.82,
     "hyperparameters": {...}
   }

4. File name: sentiment_model_v1.0_2025_12_24_acc_0.85.pkl

5. Verify: All metrics logged and documented
```

### WORKFLOW 3: Write Tests

```
1. Check: TESTING_DEPLOYMENT_RULES.md
   - Test structure (pytest)
   - Fixtures
   - Edge case examples

2. Create: tests/test_your_module.py

3. Copy template:
   import pytest
   
   class TestYourClass:
       @pytest.fixture
       def sample_data(self):
           return {...}
       
       def test_specific_behavior(self, sample_data):
           # Arrange, Act, Assert
           result = function(sample_data)
           assert result == expected

4. Write tests for:
   âœ“ Normal cases
   âœ“ Edge cases (empty, None, extreme)
   âœ“ Error conditions (should raise)
   âœ“ Different input types

5. Run: pytest --cov=src tests/
   Target: 80%+ coverage

6. If coverage < 80%:
   - Add more edge case tests
   - Test error conditions
   - Test all branches
```

### WORKFLOW 4: Deploy

```
1. Check: TESTING_DEPLOYMENT_RULES.md
   - Pre-deployment checklist
   - Production config
   - Logging setup

2. Pre-deployment (30 min):
   âœ“ All tests pass
   âœ“ 80%+ coverage
   âœ“ Code formatted (black)
   âœ“ No style issues (flake8)
   âœ“ Types correct (mypy)
   âœ“ Model meets accuracy target
   âœ“ No hardcoded credentials
   âœ“ Logging configured
   âœ“ Error handling complete
   âœ“ README updated
   âœ“ Requirements.txt has versions

3. Tag version:
   git tag -a v1.0.0 -m "Production release"
   git push origin v1.0.0

4. Deploy following your process

5. Monitor:
   - Check logs for errors
   - Monitor prediction accuracy
   - Track user feedback
```

---

## Decision Tree: Which Rule Document?

```
Do you have a question?
â”‚
â”œâ”€ "Is this allowed/forbidden?"
â”‚  â””â”€â†’ PROJECT_RULES.md (Rules section)
â”‚
â”œâ”€ "How do I organize this?"
â”‚  â””â”€â†’ PROJECT_RULES.md (Project Structure)
â”‚
â”œâ”€ "How do I name this?"
â”‚  â””â”€â†’ CODE_QUALITY_RULES.md (Naming Conventions)
â”‚
â”œâ”€ "How do I write this?"
â”‚  â””â”€â†’ CODE_QUALITY_RULES.md (Examples)
â”‚
â”œâ”€ "What's the format?"
â”‚  â”œâ”€ Type hints? â†’ CODE_QUALITY_RULES.md
â”‚  â”œâ”€ Docstrings? â†’ CODE_QUALITY_RULES.md
â”‚  â”œâ”€ Commit? â†’ PROJECT_RULES.md
â”‚  â””â”€ Model files? â†’ DATA_MODEL_RULES.md
â”‚
â”œâ”€ "How do I handle data?"
â”‚  â”œâ”€ Load? â†’ DATA_MODEL_RULES.md
â”‚  â”œâ”€ Validate? â†’ DATA_MODEL_RULES.md
â”‚  â”œâ”€ Save? â†’ DATA_MODEL_RULES.md
â”‚  â””â”€ Version? â†’ DATA_MODEL_RULES.md
â”‚
â”œâ”€ "How do I train?"
â”‚  â”œâ”€ Setup? â†’ DATA_MODEL_RULES.md
â”‚  â”œâ”€ Split? â†’ DATA_MODEL_RULES.md
â”‚  â”œâ”€ Save? â†’ DATA_MODEL_RULES.md
â”‚  â””â”€ Version? â†’ DATA_MODEL_RULES.md
â”‚
â”œâ”€ "How do I test?"
â”‚  â”œâ”€ Write tests? â†’ TESTING_DEPLOYMENT_RULES.md
â”‚  â”œâ”€ Edge cases? â†’ TESTING_DEPLOYMENT_RULES.md
â”‚  â”œâ”€ Coverage? â†’ TESTING_DEPLOYMENT_RULES.md
â”‚  â””â”€ Run tests? â†’ TESTING_DEPLOYMENT_RULES.md
â”‚
â””â”€ "How do I deploy?"
   â”œâ”€ Checklist? â†’ TESTING_DEPLOYMENT_RULES.md
   â”œâ”€ Config? â†’ TESTING_DEPLOYMENT_RULES.md
   â”œâ”€ Logging? â†’ TESTING_DEPLOYMENT_RULES.md
   â”œâ”€ Monitor? â†’ TESTING_DEPLOYMENT_RULES.md
   â””â”€ Troubleshoot? â†’ TESTING_DEPLOYMENT_RULES.md
```

---

## Tips for Efficient Usage

### ðŸ“Œ Bookmark These
- [ ] README_RULES.md (for overview)
- [ ] QUICK_REFERENCE.md (for daily use)
- [ ] Your current task's document

### ðŸ’¡ Pro Tips
1. **Keep documents in browser tabs** while working
2. **Copy code examples** - they're tested patterns
3. **Use browser search (Ctrl+F)** to find sections
4. **Follow checklists exactly** - they prevent issues
5. **Reference examples first** - then adapt to your needs

### â±ï¸ Time Estimates
- Reading full document: 30-40 minutes
- Finding specific section: 2-3 minutes
- Copying code template: 5 minutes
- Running checklist: 10-15 minutes

### ðŸ”„ Reuse Patterns
- **Docstring template** - Copy, fill in specifics
- **Test class template** - Copy, modify test names
- **Error handling pattern** - Copy, adjust error types
- **Data validation pattern** - Copy, adjust columns
- **Model metadata** - Copy, update values

---

## Troubleshooting: Can't Find Answer?

```
Lost? Try this sequence:

1. Look in QUICK_REFERENCE.md
   - Most common issues are there

2. Look in README_RULES.md
   - Common questions section
   - How to reference examples

3. Search the specific document
   - Use browser search (Ctrl+F)
   - Search for keywords

4. Check the index/table of contents
   - All major topics listed

5. Still stuck?
   - Check the "Common Mistakes" section
   - Review the decision tree above
   - Look at code examples
   - Follow the nearest checklist
```

---

## Document Relationships

```
README_RULES.md (overview & navigation)
    â”‚
    â”œâ”€â†’ QUICK_REFERENCE.md (daily reference)
    â”‚
    â”œâ”€â†’ PROJECT_RULES.md (structure & standards)
    â”‚   â””â”€â†’ General organization guidelines
    â”‚
    â”œâ”€â†’ CODE_QUALITY_RULES.md (code style)
    â”‚   â””â”€â†’ How to write Python code
    â”‚
    â”œâ”€â†’ DATA_MODEL_RULES.md (data & ML)
    â”‚   â”œâ”€â†’ How to handle data
    â”‚   â””â”€â†’ How to train models
    â”‚
    â””â”€â†’ TESTING_DEPLOYMENT_RULES.md (QA & deployment)
        â”œâ”€â†’ How to write tests
        â””â”€â†’ How to deploy

All documents cross-reference each other
with "See document_name.md - Section"
```

---

## Quick Verification: Are You Following Rules?

### âœ… Code Review Checklist (2 min)

```
â–¡ File in correct location? (check PROJECT_RULES.md)
â–¡ File named correctly? (check CODE_QUALITY_RULES.md)
â–¡ Type hints added? (check CODE_QUALITY_RULES.md)
â–¡ Docstrings complete? (check examples)
â–¡ < 50 lines per function? (CODE_QUALITY_RULES.md)
â–¡ Uses logging not print? (PROJECT_RULES.md)
â–¡ No hardcoded paths? (PROJECT_RULES.md)
â–¡ Inputs validated? (CODE_QUALITY_RULES.md)
â–¡ Error handling? (CODE_QUALITY_RULES.md)
â–¡ Tests written? (TESTING_DEPLOYMENT_RULES.md)
â–¡ All tests pass? (TESTING_DEPLOYMENT_RULES.md)
â–¡ Coverage 80%+? (TESTING_DEPLOYMENT_RULES.md)
```

### âœ… Data Review Checklist (2 min)

```
â–¡ Raw data not modified? (DATA_MODEL_RULES.md)
â–¡ Processed in data/processed/? (PROJECT_RULES.md)
â–¡ Metadata saved? (DATA_MODEL_RULES.md)
â–¡ Data validated? (DATA_MODEL_RULES.md)
â–¡ Processing steps documented? (DATA_MODEL_RULES.md)
â–¡ Versioned with date? (DATA_MODEL_RULES.md)
```

### âœ… Model Review Checklist (2 min)

```
â–¡ Seeds set? (DATA_MODEL_RULES.md)
â–¡ Proper split strategy? (DATA_MODEL_RULES.md)
â–¡ Test data not in training? (DATA_MODEL_RULES.md)
â–¡ Metadata saved? (DATA_MODEL_RULES.md)
â–¡ Correctly named? (DATA_MODEL_RULES.md)
â–¡ Metrics logged? (DATA_MODEL_RULES.md)
```

---

**Created:** December 2025
**Version:** 1.0
**Use this with the other rule documents for best results!**
