# ğŸ“‹ SENTIMENT ANALYSIS PROJECT - RULES INDEX

## Welcome! ğŸ‘‹

You now have **5 comprehensive rules documents** to keep your Sentiment Analysis project organized, maintainable, and professional.

---

## ğŸ“š Your Rules Documents

### 1. **QUICK_REFERENCE.md** â­ START HERE
**Best for:** Quick lookups and checklists
- Quick start checklist
- Key rules at a glance
- Common mistakes to avoid
- Performance targets
- Deployment readiness checklist

ğŸ‘‰ **When to use:** Before starting work each day

---

### 2. **PROJECT_RULES.md** ğŸ“
**Best for:** Overall project structure and standards
- Project directory structure
- Code organization guidelines
- Naming conventions for files/folders
- Git & version control rules
- Performance & optimization standards

**Key Sections:**
- Project Structure Rules (how to organize files)
- Code Quality Rules (general standards)
- Data Handling Rules (data integrity)
- Model Training Rules (training best practices)
- Testing & Validation Rules (test coverage targets)
- Documentation Rules (what to document)
- Git & Version Control Rules (commit standards)
- Performance & Optimization Rules (speed targets)

ğŸ‘‰ **When to use:** Setting up project, organizing code

---

### 3. **CODE_QUALITY_RULES.md** ğŸ
**Best for:** Python code style and quality standards
- Naming conventions (PEP 8)
- Type hints requirements
- Docstring format (Google style)
- Line length & formatting
- Error handling patterns
- Class structure
- Common mistakes to avoid

**Key Code Examples:**
- âœ… CORRECT code examples
- âŒ WRONG code examples with explanations

**Metrics:**
- Cyclomatic complexity limits
- Code coverage targets
- Performance standards

ğŸ‘‰ **When to use:** Writing Python code, doing code reviews

---

### 4. **DATA_MODEL_RULES.md** ğŸ¯
**Best for:** Data handling and model management
- Data pipeline standards
  - Raw data handling (read-only)
  - Data processing (with metadata)
  - Data validation (before training)
- Text quality checks
- Data preprocessing standards
- Model training setup
- Train/test/validation split strategy
- Model versioning & naming
- Evaluation & metrics collection

**Key Code Examples:**
- Data validation functions
- Text preprocessing
- Metadata saving
- Model evaluation

ğŸ‘‰ **When to use:** Loading data, training models, saving results

---

### 5. **TESTING_DEPLOYMENT_RULES.md** ğŸš€
**Best for:** Testing and deployment procedures
- Unit testing structure
- Test coverage standards by module
- Edge case testing
- Integration testing
- Pre-deployment checklist
- Production configuration
- Logging setup
- Monitoring & maintenance
- Model retraining rules
- Performance standards
- Troubleshooting guide

**Key Code Examples:**
- Pytest fixtures and tests
- Production logging configuration
- Edge case test examples
- Troubleshooting patterns

ğŸ‘‰ **When to use:** Writing tests, deploying to production

---

## ğŸ¯ How to Use These Rules

### Daily Development Workflow

#### ğŸ“– Morning: Check Quick Reference
```bash
# Review what you need to do today
cat QUICK_REFERENCE.md
```
- Check the relevant checklist
- See performance targets
- Remember critical rules

#### ğŸ’» Writing Code
```bash
# While writing Python
cat CODE_QUALITY_RULES.md
```
- Follow naming conventions
- Add type hints (copy examples if needed)
- Write docstrings (use Google style examples)

#### ğŸ—‚ï¸ Organizing Files
```bash
# Setting up new modules/data
cat PROJECT_RULES.md
```
- Find correct directory structure
- Naming conventions for files
- Directory organization patterns

#### ğŸ“Š Handling Data
```bash
# Loading and processing data
cat DATA_MODEL_RULES.md
```
- Data validation checklist
- Preprocessing examples
- Model versioning format

#### âœ… Testing Code
```bash
# Writing and running tests
cat TESTING_DEPLOYMENT_RULES.md
```
- Unit test structure (copy the class template)
- Edge case examples
- Coverage targets

---

## ğŸ”‘ Critical Rules Summary

### ğŸš« NEVER Do This
```
1. âŒ Modify files in data/raw/
2. âŒ Hardcode file paths
3. âŒ Use print() in production code
4. âŒ Train on test data
5. âŒ Commit model files to git
6. âŒ Skip input validation
7. âŒ Ignore error handling
8. âŒ Use global variables
9. âŒ Commit without tests passing
10. âŒ Deploy without documentation
```

### âœ… ALWAYS Do This
```
1. âœ… Set random seeds (reproducibility)
2. âœ… Write type hints (self-documenting)
3. âœ… Add docstrings (all functions)
4. âœ… Validate inputs (error prevention)
5. âœ… Use logging (debugging)
6. âœ… Save model metadata (traceability)
7. âœ… Version data/models (reproducibility)
8. âœ… Write tests (quality assurance)
9. âœ… Document assumptions (clarity)
10. âœ… Review code before merging (quality)
```

---

## ğŸ“Š File Organization Template

Use this structure for your project:
```
sentiment-analysis-project/
â”‚
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sentiment_analyzer.py
â”‚   â”œâ”€â”€ text_preprocessor.py
â”‚   â”œâ”€â”€ train_models.py
â”‚   â”œâ”€â”€ predict.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ helpers.py
â”‚
â”œâ”€â”€ data/                         # Data files
â”‚   â”œâ”€â”€ raw/                      # NEVER MODIFY
â”‚   â”‚   â””â”€â”€ reviews_2025_12_24.csv
â”‚   â”œâ”€â”€ processed/                # Your working data
â”‚   â”‚   â””â”€â”€ processed_reviews_2025_12_24.csv
â”‚   â””â”€â”€ test/
â”‚
â”œâ”€â”€ models/                       # Trained models
â”‚   â”œâ”€â”€ sentiment_model_v1.0_2025_12_24_acc_0.85.pkl
â”‚   â””â”€â”€ sentiment_model_v1.0_2025_12_24_metadata.json
â”‚
â”œâ”€â”€ tests/                        # Test files
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_sentiment_analyzer.py
â”‚   â”œâ”€â”€ test_preprocessor.py
â”‚   â””â”€â”€ test_models.py
â”‚
â”œâ”€â”€ config/                       # Configuration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ development.py
â”‚   â””â”€â”€ production.py
â”‚
â”œâ”€â”€ logs/                         # Application logs
â”‚   â””â”€â”€ app.log
â”‚
â”œâ”€â”€ results/                      # Experiment results
â”‚   â””â”€â”€ results_2025_12_24_15_30_45.json
â”‚
â”œâ”€â”€ examples/                     # Example scripts
â”‚   â””â”€â”€ basic_usage.py
â”‚
â”œâ”€â”€ notebooks/                    # Jupyter notebooks
â”‚   â””â”€â”€ exploration.ipynb
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ QUICK_REFERENCE.md           â­ YOU ARE HERE
â”œâ”€â”€ PROJECT_RULES.md
â”œâ”€â”€ CODE_QUALITY_RULES.md
â”œâ”€â”€ DATA_MODEL_RULES.md
â””â”€â”€ TESTING_DEPLOYMENT_RULES.md
```

---

## ğŸš€ Quick Start Paths

### "I'm just starting"
1. Read: **QUICK_REFERENCE.md**
2. Read: **PROJECT_RULES.md** (Project Structure section)
3. Create project folders following the template above
4. Read: **CODE_QUALITY_RULES.md**

### "I'm writing code"
1. Check: **CODE_QUALITY_RULES.md** (naming, type hints, docstrings)
2. Reference: Examples in the document
3. Check: **QUICK_REFERENCE.md** (before committing)

### "I'm handling data"
1. Check: **DATA_MODEL_RULES.md**
2. Follow: Data validation checklist
3. Save: Metadata with processed data
4. Document: All preprocessing steps

### "I'm training a model"
1. Check: **DATA_MODEL_RULES.md** (Model Training section)
2. Follow: Pre-training checklist
3. Set: Random seeds
4. Save: Model with metadata
5. Log: All metrics

### "I'm writing tests"
1. Check: **TESTING_DEPLOYMENT_RULES.md**
2. Copy: Test class template
3. Write: Tests following pattern
4. Run: `pytest --cov=src tests/`
5. Verify: 80%+ coverage

### "I'm deploying"
1. Check: **TESTING_DEPLOYMENT_RULES.md** (Pre-Deployment section)
2. Run: Full checklist
3. Tag: Version in git
4. Deploy: Following checklist
5. Monitor: Following monitoring rules

---

## ğŸ“– How to Reference Examples

All rules documents include code examples:

### âœ… CORRECT Examples
These show the right way to do things.
```python
# âœ… CORRECT
class SentimentAnalyzer:
    def __init__(self, model_type: str = 'logistic_regression'):
        self.model_type = model_type
        self.is_trained = False
```

**Copy this pattern when you write similar code.**

### âŒ WRONG Examples
These show what NOT to do.
```python
# âŒ WRONG
class sentiment_analyzer:  # Should be PascalCase
    def __init__(self, MT='lr'):  # Unclear abbreviations
        self.mod = MT  # Bad variable name
```

**Avoid this pattern.**

---

## ğŸ“ Learning Path

### Week 1: Foundations
- [ ] Read QUICK_REFERENCE.md completely
- [ ] Read PROJECT_RULES.md structure section
- [ ] Read CODE_QUALITY_RULES.md
- [ ] Create proper project structure
- [ ] Write first module following rules

### Week 2: Data & Models
- [ ] Read DATA_MODEL_RULES.md
- [ ] Load and validate data
- [ ] Train first model
- [ ] Save model with metadata
- [ ] Document all steps

### Week 3: Testing & Quality
- [ ] Read TESTING_DEPLOYMENT_RULES.md
- [ ] Write unit tests
- [ ] Achieve 80%+ coverage
- [ ] Run code quality checks
- [ ] Fix any issues

### Week 4: Production
- [ ] Set up logging
- [ ] Run pre-deployment checklist
- [ ] Tag version in git
- [ ] Deploy following procedures
- [ ] Monitor results

---

## ğŸ¤” Common Questions

### Q: Where should I put my data?
**A:** See **PROJECT_RULES.md** - Project Structure section
- Raw data: `data/raw/` (read-only)
- Working data: `data/processed/`
- Test data: `data/test/`

### Q: How should I name variables?
**A:** See **CODE_QUALITY_RULES.md** - Naming Conventions
- Variables: `snake_case`
- Classes: `PascalCase`
- Constants: `UPPERCASE`

### Q: Can I modify raw data files?
**A:** NO! See **DATA_MODEL_RULES.md** - Data Handling Rules
- Raw data is read-only
- Always work in `data/processed/`

### Q: What should model files be named?
**A:** See **DATA_MODEL_RULES.md** - Model Versioning Rules
- Pattern: `model_name_v1.0_2025_12_24_acc_0.85.pkl`

### Q: How much test coverage do I need?
**A:** See **TESTING_DEPLOYMENT_RULES.md** - Test Coverage Standards
- Minimum: 80%
- Critical modules: 90%
- Run: `pytest --cov=src tests/`

### Q: What's the deployment checklist?
**A:** See **TESTING_DEPLOYMENT_RULES.md** - Pre-Deployment Checklist
- Tests passing
- 80%+ coverage
- Code style clean
- Logging configured
- Etc.

---

## âœ¨ Pro Tips

1. **Keep this index file open** while working
2. **Bookmark the most relevant rule file** for your current task
3. **Copy code examples** from the documents
4. **Check checklists** before major changes
5. **Reference patterns** when writing similar code
6. **Ask "what does the rule say?"** when uncertain

---

## ğŸ“ When to Reference

| Situation | Document |
|-----------|----------|
| "What should I do first?" | QUICK_REFERENCE.md |
| "How do I name this?" | CODE_QUALITY_RULES.md |
| "Where do I save files?" | PROJECT_RULES.md |
| "How do I preprocess data?" | DATA_MODEL_RULES.md |
| "How do I write tests?" | TESTING_DEPLOYMENT_RULES.md |
| "Can I modify raw data?" | DATA_MODEL_RULES.md |
| "How do I commit?" | PROJECT_RULES.md |
| "Is my code ready?" | QUICK_REFERENCE.md (Checklist) |
| "How do I deploy?" | TESTING_DEPLOYMENT_RULES.md |

---

## ğŸ‰ You're Ready!

You now have everything you need to:

âœ… Organize your project properly
âœ… Write clean, professional code
âœ… Handle data correctly
âœ… Train and version models
âœ… Write comprehensive tests
âœ… Deploy with confidence
âœ… Maintain code quality

**Next Step:** Pick the task you're starting with and reference the appropriate document!

---

**Created:** December 2025
**Version:** 1.0
**Status:** Ready to use

ğŸ’¡ **Pro Tip:** Bookmark this file and the QUICK_REFERENCE.md for daily use!
