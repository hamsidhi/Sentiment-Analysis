# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
pip-wheel-metadata/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual Environments
venv/
env/
ENV/
.venv/
env.bak/

# IDE & Editors
.vscode/
.idea/
*.swp
*.swo
*~
.DS_Store
.project
.pydevproject
.settings/
*.sublime-project
*.sublime-workspace

# OS Generated Files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Environment Variables
.env
.env.local
.env.*.local
.env.backup*

# PROCESSED DATA (500MB+ - regenerate from raw)
data/processed/
data/processed/*.csv
data/processed/*.parquet
data/processed/*.json

# TRAINED MODELS (200MB+ - retrain locally)
models/
models/*.pkl
models/*.joblib
models/*.pth
models/*.onnx
models/*.h5
*.pkl
*.joblib
*.pth
*.onnx
*.h5

# REPORTS & VISUALIZATIONS (100MB+ - regenerate)
reports/
reports/*/
*.png
*.jpg
*.jpeg
*.pdf
*.html
visualizations/

# Temporary & Cache Files
.cache/
temp/
tmp/
temp_download/
*.tmp
*.temp
download_cache/

# ... [rest of standard rules remain same] ...

# ⚠️ DATASET RULES - CRITICAL FIX ⚠️
# BLOCK FULL DATASETS (1.6GB+)
data/raw/*.csv
data/raw/*.json
data/raw/*.parquet
data/raw/*.zip
data/raw/*.gz

# BUT ALLOW SAMPLES (600KB total - for demo)
!data/raw/*_sample.csv
!data/raw/amazon_sample.csv
!data/raw/"BITS Pilani_sample.csv"
!data/raw/"IMDB Dataset_sample.csv"
!data/raw/movies_sample.csv
!data/raw/twitter_sample.csv

# BLOCK SPECIFIC FULL DATASETS (redundant but explicit)
data/raw/amazon.csv
data/raw/"BITS Pilani.csv"
data/raw/"IMDB Dataset.csv"
data/raw/movies.csv
data/raw/twitter.csv
data/raw/huggingface_*.csv
data/raw/huggingface_*.json

# ... [rest of your rules remain same] ...
